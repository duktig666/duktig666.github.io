---
title: Kafka基础
date: 2022-03-07 
publish: false
---

## Kafka生产者

一个应用程序在很多情况下需要往 Kafka 写入消息 ： 记录用户的活动（用于审计和分析）、记录度量指标、保存日志消息、记录智能家电的信息、与其他应用程序进行异步通信、 缓冲即将写入到数据库的数据，等等。

多样的使用场景意味着多样的需求：**是否每个消息都很重要？是否允许丢失一小部分消息？偶尔出现重复消息是否可以接受？是否有严格的延迟和吞吐量要求？**

不同的使用场景对生产者 API 的使用和配置会有直接的影响。

### 向Kafka发送消息的步骤

![image-20220310153515464](https://cos.duktig.cn/typora/202203101535042.png)

从创建一个 **ProducerRecord** 对象开始， ProducerRecord 对象需要包含 **目标主题** 和 **要发送的内容**。我们还可以 **指定键或分区**。在发送 ProducerRecord 对象时，生产者要先把键和值对象 **序列化成字节数组**，这样它们才能够在网络上传输。

接下来，数据被传给分区器。如果之前在 ProducerRecord  对象里指定了分区，那么分区器就不会再做任何事情，直接把指定的分区返回。如果没有指定分区 ，那么分区器会根据ProducerRecord  对象的键来选择一个分区 。选好分区以后 ，生产者就知道该往哪个主题和分区发送这条记录了。

**这条记录被添加到一个记录批次里，这个批次里的所有消息会被发送到相同的主题和分区上**。有一个独立的线程负责把这些记录批次发送到相应的 broker 上。

服务器在收到这些消息时会返回一个响应。如果消息成 功写入 Kafka ，就返回 一 个**RecordMetaData** 对象，**它包含了主题和分区信息，以及记录在分区里的偏移量**。如果写入失败， 则会返回 一个错误。**生产者在收到错误之后会尝试重新发送消息，几次之后如果还是失败， 就返回错误信息**。

创建生产者：

```java
private Prpperties kafkaProps = new Properties();
kafkaProps.put( "bootstrap.servers"，"broker1:9092,broker2:9092");
kafkaProps.put( "key.serializer","org.apache.kafka.connon.serialization.StringSerializer");
kafkaProps.put( "value.serializer","org.apache.kafka.common.serialization.StringSerializer");
producer = new KafkaProducer<String,String>(kafkaProps);
```



### 生产者发送消息

生产者发送消息主要有以下 3 种方式：

**1、发送并忘记**

把消息发送给服务器，但井不关心它是否正常到达。大多数情况下，消息会正常到达，因为 Kafka 是高可用的，而且生产者会自动尝试重发。不过，使用这种方式有时候也会丢失一些消息。

```java
ProducerRecord<String,String; record =
    new ProducerRecord<>( "CustonerCountry" , "Precision Products","France");

try {
    producer.send(record); 
}catch (Exception e) {
    e.printStackTrace(); 
}
```

我们使用生产者的send()方法发送ProducerRecord对象。

从生产者的架构图里可以看到，**消息先是被放进缓冲区，然后使用单独的线程发送到服务器端**。

send()方法会返回一个包含`RecordMetadata`的 `Future`对象，**不过因为我们会忽略返回值，所以无法知道消息是否发送成功**。

**如果不关心发送结果，那么可以使用这种发送方式**。比如，记录Twitter消息日志，或记录不太重要的应用程序日志。

在发送消息之前，生产者还是有可能发生其他的异常。这些异常有可能是 SerializationException（说明序列化消息失败）、 BufferExhaustedException 或 TimeoutException （说明缓冲区已满），又或者是 InterruptException （说明发送线程被中断）。

**2、同步发送**

使用 `send()` 方怯发送消息 ， 它会返回一个 `Future对象`，调用 `get()` 方法进行等待 ，就可以知道悄息是否发送成功。

```java
producer.send(record).get();
```

在这里，producer.send()方法先返回一个Future对象，然后调用Future对象的get()方法等待Kafka响应。如果服务器返回错误，get()方法会抛出异常。如果没有发生错误，我们会得到一个 RecordMetadata对象，可以用它获取消息的偏移量。

KafkaProducer一般会发生两类错误：

- 其中一类是**可重试错误**，这类错误可以通过重发消息来解决。
  - 比如对于连接错误，可以通过再次建立连接来解决，
  - “无主(no leader)”错误则可以通过重新为分区选举首领来解决。
  - KafkaProducer可以被配置成自动重试，如果在多次重试后仍无法解决问题，应用程序会收到一个重试异常。

- 另一类错误无法通过重试解决，比如“消息大大”异常。对干这类错误，KafkaProducer不会进行任何重试，直接抛出异常。

**3、异步发送**

调用 `send()` 方怯，并指定一个回调函数， 服务器在返回响应时调用该函数。

为了在异步发送消息的同时能够对异常情况进行处理，生产者提供了 **回调** 支持。

```java
private class DemoProducerCallback implenents Callback {
    @0verride
    public void onCompletion(RecordMetadata recordMetadata，Exception e) {
        if (e != null) {
            e.printStackTrace();
        }
    } 
}
ProducerRecord<String,String> record =
    new ProducerRecord<>("CustonerCountry","Bionedical Materials","USA");
producer.send(record，new DemoProducerCallback());
```



### 生产者配置

生产者还有很多可配置 的 参数，在 Kafka 文档里都有说明，它们大部分都有合理的默认值 ， 所以没有必要去修改它们 。不过有几个参数在内存使用、性能和可靠性方面对生产者影响比较大。

####  acks

acks 参数指定了 **必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的** 。这个参数对消息丢失的可能性有重要影响。主参数有如下选项：

- 如果 `acks=0` ， **生产者在成功写入悄息之前不会等待任何来自服务器的响应**。也就是说，如果当中出现了问题 ， 导致服务器没有收到消息，那么生产者就无从得知，消息也就丢失了。不过，因为生产者不需要等待服务器的响应，所以它可以以网络能够支持的最大速度发送消息，从而达到很高的吞吐量。
- 如果 `acks=1` ，**只要集群的首领节点收到消息，生产者就会收到一个来自服务器的成功响应**。如果一个没有收到消息的节点成为新首领，消息还是会丢失。
- 如果 `acks=all `，只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。这种模式是最安全的，它可以保证不止一个服务器收到消息，就算有服务器发生崩溃，整个集群仍然可以运行

#### buffer.memory

该参数用来 **设置生产者内存缓冲区的大小**，**生产者用它缓冲要发送到服务器的消息**。

如果应用程序发送消息的速度超过发送到服务器的速度，会导致生产者空间不足。这个时候，`send()` 方法调用要么被阻塞，要么抛出异常， `max.block.ms`，表示在抛出异常之前可以阻塞一段时间。

####  compression.type

默认情况下，消息发送时不会被压缩。该参数可以设置为 snappy 、 gzip 或 lz4 ，它指定了 **消息被发送给 broker 之前使用哪一种压缩算也进行压缩**。 

snappy 压缩算法田 Google发明，它占用较少的CPU，却能提供较好的性能和相当可观的压缩比，如果比较关注性能和网络带宽，可以使用这种算法。

gzip压缩算法一般会占用较多的CPU，但会提供更高的压缩比，所以如果网络带宽比较有限，可以使用这种算法。使用压缩可以降低网络传输开销和存储开销，而这往往是向Kafka发送消息的瓶颈所在。

#### retries

生产者从服务器收到的错误有可能是临时性的错误（比如分区找不到首领）。在这种情况下， **retries 参数的值决定了生产者可以重发消息的次数，如果达到这个次数，生产者会放弃重试并返回错误**。

默认情况下，生产者会在每次重试之间等待 100ms ，不过可以通过`retry.backoff.ms` 参数来改变这个时间间隔。

建议在设置重试次数和重试时间间隔之前，先测试一下恢复一个崩愤节点需要多少时间（比如所有分区选举出首领需要多长时间），让总的重试时间比 Kafka 集群从崩愤中恢复的时间长，否则生产者会过早地放弃重试。

#### batch.size

当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。**该参数指定了一个批次可以使用的内存大小，按照字节数计算（而不是消息个数）**。

当批次被填满，批次里的所有消息会被发送出去。**不过生产者井不一定都会等到批次被填满才发送，半满的批次，甚至只包含一个消息的批次也有可能被发送。所以就算把批次大小设置得很大，也不会造成延迟，只是会占用更多的内存而已**。

**但如果设置得太小，因为生产者需要更频繁地发送消息，会增加一些额外的开销**。

#### linger.ms

该参数指定了 **生产者在发送批次之前等待更多消息加入批次的时间** 。 

 KafkaProducer 会在批次填满 或 linger.ms 达到上限时把批次发送出去。默认情况下，只要有可用的线程， 生产者就会把消息发送出去，就算批次里只有一个消息。

把 linger.ms 设置成比 0 大的数，让生产者在发送批次之前等待一会儿，使更多的消息加入到这个批次。虽然这样会增加延迟，但也会提升吞吐量（因为一次性发送更多的消息，每个消息的开销就变小了） 。

#### client.id 

该参数可以是任意的字符串，服务器会用它来识别消息的来橱，还可以用在日志和配额指标里。

#### max.in.flight.requests.per.connection

该参数指定了 **生产者在收到服务器晌应之前可以发送多少个消息**。

它的值越高，就会占用越多的内存，不过也会提升吞吐量。 **把它设为 1 可以保证消息是按照发送的顺序写入服务器的，即使发生了重试**。

#### timeout.ms 、 request.timeout.ms 和 metadata. fetch. timeout. ms

request.timeout.ms 指定了生产者在发送数据时等待服务器返回响应的时间

metadata. fetch. timeout. ms 指定了生产者在获取元数据（比如目标分区的首领是谁）时等待服务器返回响应的时间。如果等待响应超时，那么生产者要么重试发送数据，要么返回一个错误（抛出异常或执行回调）。

timeout.ms  指定了 bro ker 等待同步副本返回消息确认的时间，与 asks 的配置相匹配一一如果在指定时间内没有收到同步副本的确认，那么 broker 就会返回一个错误。

#### max.block.ms 

该参数指定了在调用 `send()`方法或使用 `partitionsFor() `方法能获取元数据时生产者的阻塞时间。

当生产者的发送缓冲区已满，或者没有可用的元数据时，这些方屈就会阻塞。在阻塞时间达到 max.block.ms 时，生产者会抛出超时异常。

#### max.request.size 

**该参数用于控制生产者发送的请求大小**。它可以指能发送的单个消息的最大值，也可以指单个请求里所有消息总的大小。

例如，假设这个值为 1MB ，那么可以发送的单个最大消息为 1MB ，或者生产者可以在单个请求里发送一个批次，该批次包含了 1000 个消息，每个消息大小为 1 阻。另外， broker 对可接收的消息最大值也有自己的限制（message. max. bytes），所以两边的配置最好可以匹配，避免生产者发送的消息被 broker 拒绝。

#### receive.buffer.bytes 和 send.buffer.bytes

这两个参数分别指定了 TCP socket 接收和发送数据包的缓冲区大小。 如果它们被设为 -1 ,就使用操作系统的默认值。

如果生产者或消费者与 broker 处于不同的数据中心，那么可以适当增大这些值，因为跨数据中心的网络一般都有比较高的延迟和比较低的带宽。

### 顺序保证

**Kafka 可以保证同一个分区里的消息是有序的**。

也就是说，如果生产者按照一定的顺序发送消息， broker 就会按照这个顺序把它们写入分区，消费者也会按照同样的顺序去读取它们。

在某些情况下 ， 顺序是非常重要的。例如，往一个账户存入 100 元再取出来，这个与先取钱再存钱是截然不同的！不过，有些场景对顺序不是很敏感。

**如果把 retries 设为非零整数，同时把 max.in.flight.requests.per.connection 设为比 1 大的数，那么，如果第一个批次消息写入失败，而第二个批次写入成功， broker 会重试写入第一个批次。如果此时第一个批次也写入成功，那么两个批次的顺序就反过来了。**

一般来说，如果某些场景要求消息是有序的，那么消息是否写入成功也是很关键的，所以不建议把 retries 设为 0 。可以把 max.in.flight.requests.per.connection 设为 1 ，这样在生产者尝试发送第一批悄息时，就不会有其他的消息发送给 broker 。不过这样会严重影响生产者的吞吐量 ，所以 只有在对消息的顺序有严格要求的情况下才能这么做。

### 分区

Kafka 的消息是一个个键值对，ProducerRecord 对象可以只包含目标主题和值，键可以设置为默认的 null ，不过大多数应用程序会用到键。

**键有两个用途 ：可以作为消息的附加信息，也可以用来决定消息该被写到主题的哪个分区。拥有相同键的悄息将被写到同 一个分区。** 

如果键值为 null ， 井且使用了默认的分区器，那么记录将被随机地发送到主题内各个可用的分区上。分区器使用轮询（Round Robin）算陆将消息均衡地分布到各个分区上。

如果键不为空，并且使用了默认的分区器，那么 Kafka 会对键进行散列（使用 Kafka 自己的散列算法，即使升级 Java 版本，散列值也不会发生变化），然后根据散列值把消息映射到特定的分区上。

**只有在不改变主题分区数量的情况下，键与分区之间的映射才能保持不变。一旦主题增加了新的分区，这些就无陆保证了。**

**如果要使用键来映射分区，那么最好在创建主题的时候就把分区规划好，而且永远不要增加新分区。**

## Kafka消费者



