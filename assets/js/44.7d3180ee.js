(window.webpackJsonp=window.webpackJsonp||[]).push([[44],{471:function(v,_,a){"use strict";a.r(_);var t=a(3),r=Object(t.a)({},(function(){var v=this,_=v._self._c;return _("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[_("h2",{attrs:{id:"简介"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#简介"}},[v._v("#")]),v._v(" 简介")]),v._v(" "),_("p",[v._v("Kafka 是一款基于发布与订阅的梢息系统，它一般被称为“分布式提交日志”或者“分布式流平台”。")]),v._v(" "),_("p",[v._v("Kafka 是为了解决 LinkedIn 数据管道问题应运而生的。它的设计目的是提供一个高性能的悄息系统，可以处理多种数据类型，并能够实时提供纯净且结构化的用户活动数据和系统度量指标。")]),v._v(" "),_("p",[v._v("Linked In 有一个比较复杂的用户请求跟踪功能。它使用了监控系统，可以跟踪单个用户的请求是如何在内部应用间传播的。")]),v._v(" "),_("ul",[_("li",[v._v("监控系统存在很多不足。它使用的是轮询拉取度量指标的方式，指标之间的时间间隔较长，而且没有自助服务能力 。它使用起来不太方便，很多简单的任务需要人工介入才能完成，而且一致性较差，同一个度量指标的名字在不同系统里的叫法不一样。")]),v._v(" "),_("li",[v._v("创建了另一个用于收集用户活动信息的系统。这是一个 HTIP 服务，前端的服务器会定期连接进来，在上面发布一些消息（ XML 格式）。这些消息文件被转移到线下进行解析和校对。同样，这个系统也存在很多不足 ：\n"),_("ul",[_("li",[_("strong",[v._v("XML 文件的格式无桂保持一致")]),v._v("，")]),v._v(" "),_("li",[_("strong",[v._v("解析 XML 文件非常耗费计算资源")]),v._v("。")]),v._v(" "),_("li",[v._v("要想更改所创建的活动类型， 需要在前端应用和离线处理程序之间做大量的协调工作。即使是这样，在更改数据结构时，仍然经常出现系统崩愤现象。")]),v._v(" "),_("li",[v._v("批处理时间以小时计算，无法用它完成实时的任务 。")])])]),v._v(" "),_("li",[_("strong",[v._v("监控和用户活动跟踪无陆使用同一个后端服务")]),v._v("。\n"),_("ul",[_("li",[v._v("监控服务太过笨重，数据格式不适用于活动跟踪，而且无住在活动跟踪中使用轮询拉取模型")]),v._v(" "),_("li",[v._v("把跟踪服务用在度量指标上也过于脆弱，批处理模型不适用于实时的监控和告警")])])]),v._v(" "),_("li",[v._v("使用 ActiveMQ 创建了一个原型系统，但它当时还 "),_("strong",[v._v("无法满足横向扩展的需求")]),v._v("。ActiveMQ 有很多触陷会导致 broker 暂停服务。客户端的连接因此被阻塞，处理用户请求的能力也受到影响。")])]),v._v(" "),_("h3",{attrs:{id:"kafka的设计目标"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#kafka的设计目标"}},[v._v("#")]),v._v(" Kafka的设计目标")]),v._v(" "),_("p",[v._v("主要目标如下：")]),v._v(" "),_("ul",[_("li",[v._v("使用推送和拉取模型解耦生产者和消费者")]),v._v(" "),_("li",[v._v("为消息传递系统中的消息提供数据持久化，以便支持多个消费者")]),v._v(" "),_("li",[v._v("通过系统优化实现高吞吐量")]),v._v(" "),_("li",[v._v("系统可以随着数据流的增长进行横向扩展。")])]),v._v(" "),_("h3",{attrs:{id:"kafka的一些概念"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#kafka的一些概念"}},[v._v("#")]),v._v(" Kafka的一些概念")]),v._v(" "),_("h4",{attrs:{id:"消息、键、批次"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#消息、键、批次"}},[v._v("#")]),v._v(" 消息、键、批次")]),v._v(" "),_("p",[v._v("Kafka 的数据单元被称为"),_("strong",[v._v("消息")]),v._v("。")]),v._v(" "),_("p",[v._v("消息可以有一个可选的元数据 ，也就是 "),_("strong",[v._v("键")]),v._v("。 当 消息以一种可控的方式写入不同的分区时，会用到键。最简单的例子就是为键生成一个一致性散列值，然后使用散列值对主题分区数进行取模，为消息选取分区 。这样可以"),_("strong",[v._v("保证具有相同键的消息总是被写到相同的分区上")]),v._v("。")]),v._v(" "),_("p",[v._v("为了提高效率，消息被分批次写入 Kafka 。 "),_("strong",[v._v("批次就是一组消息，这些消息属于同一个主题和分区")]),v._v("。")]),v._v(" "),_("p",[v._v("批次数据会被"),_("strong",[v._v("压缩")]),v._v("，这样可以提升数据的传输和存储能力，但要做更多的计算处理。")]),v._v(" "),_("h4",{attrs:{id:"主题和分区"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#主题和分区"}},[v._v("#")]),v._v(" 主题和分区")]),v._v(" "),_("p",[v._v("Kaflca 的悄息通过 "),_("strong",[v._v("主题")]),v._v(" 进行分类。主题就好比数据库的表，或者文件系统里的文件夹。主题可以被分为若干个 "),_("strong",[v._v("分区")]),v._v("  ， 一个分区就是一个提交日志。")]),v._v(" "),_("p",[_("strong",[v._v("消息以追加的方式写入分区，然后以先入先出的顺序读取")]),v._v("。要注意，由于一个主题一般包含几个分区，因此"),_("strong",[v._v("无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序")]),v._v("。")]),v._v(" "),_("p",[v._v("我们通常会使用 "),_("strong",[v._v("流")]),v._v(" 这个词来描述 Kaflca 这类系统的数据，人们把一个主题的数据看成一个流，不管它有多少个分区。"),_("strong",[v._v("流是一组从生产者移动到消费者的数据")]),v._v("。")]),v._v(" "),_("h4",{attrs:{id:"生产者和消费者"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#生产者和消费者"}},[v._v("#")]),v._v(" 生产者和消费者")]),v._v(" "),_("p",[_("strong",[v._v("生产者创建消息")]),v._v("。")]),v._v(" "),_("p",[v._v("生产者在"),_("strong",[v._v("默认情况下把消息均衡地分布到主题的所有分区上")]),v._v("，而并不关心特定消息会被写到哪个分区。")]),v._v(" "),_("p",[_("strong",[v._v("在某些情况下，生产者会把消息直接写到指定的分区")]),v._v("。这通常是通过消息键和分区器来实现的，分区器为键生成一个散列值，并将其映射到指定的分区上。这样可以保证包含同一个键的消息会被写到同一个分区上。生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区。")]),v._v(" "),_("p",[_("strong",[v._v("消费者读取消息")]),v._v("。")]),v._v(" "),_("p",[_("strong",[v._v("消费者通过检查消息的偏移盘来区分已经读取过的消息")]),v._v("。 偏移量是另一种元数据，它是一个不断递增的整数值，在创建消息时，Kafka 会把它添加到消息里。"),_("strong",[v._v("在给定的分区里，每个悄息的偏移量都是唯一的")]),v._v("。")]),v._v(" "),_("p",[v._v("消费者把每个分区最后读取的悄息偏移量保存在 Zoo keeper 或 Kafka 上，如果悄费者关闭或重启，它的读取状态不会丢失。")]),v._v(" "),_("p",[v._v("消费者是 "),_("strong",[v._v("消费者群组")]),v._v(" 的一部分，也就是说，会有一个或多个消费者共同读取一个主题。 群组保证每个分区只能被一个消费者使用 。")]),v._v(" "),_("h4",{attrs:{id:"broker和集群"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#broker和集群"}},[v._v("#")]),v._v(" broker和集群")]),v._v(" "),_("p",[v._v("一个独立的 Kafka 服务器被称为 broker 。")]),v._v(" "),_("ul",[_("li",[v._v("broker 接收来自 生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。")]),v._v(" "),_("li",[v._v("broker 为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息。")])]),v._v(" "),_("p",[v._v("broker 是集群的组成部分。每个集群都有一个 broker 同时充当了 "),_("strong",[v._v("集群控制器")]),v._v(" 的角色（自动从集群的活跃成员中选举出来）。")]),v._v(" "),_("p",[v._v("控制器负责管理工作，包括将分区分配给 broker 和监控broker。在集群中")]),v._v(" "),_("ul",[_("li",[v._v("一个分区从属于一个 broker, 该broker 被称为分区的首领。")]),v._v(" "),_("li",[v._v("一个分区可以分配给多个 broke r ，这个时候会发生"),_("strong",[v._v("分区复制")]),v._v("。")])]),v._v(" "),_("p",[v._v("这种复制机制为分区提供了消息冗余，"),_("strong",[v._v("如果有一个 broker 失效，其他 broker 可以接管领导权")]),v._v("。不过，"),_("strong",[v._v("相关的消费者和生产者都要重新连接到新的首领")]),v._v("。")]),v._v(" "),_("h4",{attrs:{id:"保留消息"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#保留消息"}},[v._v("#")]),v._v(" 保留消息")]),v._v(" "),_("p",[v._v("保留消息（在一定期限内）是 Kafka 的一个重要特性。 Kafka broker 默认的消息保留策略是这样的：")]),v._v(" "),_("ul",[_("li",[v._v("要么保留一段时间（比如 7 天），")]),v._v(" "),_("li",[v._v("要么保留到消息达到一定大小的字节数（比如 lGB ）。")])]),v._v(" "),_("p",[v._v("当消息数量达到这些上限时，旧消息就会过期井被删除，所以在任何时刻， "),_("strong",[v._v("可用消息的总量都不会超过配置参数所指定的大小")]),v._v("。")]),v._v(" "),_("h4",{attrs:{id:"多集群"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#多集群"}},[v._v("#")]),v._v(" 多集群")]),v._v(" "),_("p",[v._v("随着 Kafka 部署数量的增加，基于以下几点原因，最好使用多个集群。")]),v._v(" "),_("ul",[_("li",[v._v("数据类型分离")]),v._v(" "),_("li",[v._v("安全需求隔离")]),v._v(" "),_("li",[v._v("多数据中心（灾难恢复）")])]),v._v(" "),_("p",[v._v("如果使用多个数据中心，就需要在它们之间复制消息。这样，在钱应用程序才可以访问到多个姑点的用户活动信息。")]),v._v(" "),_("p",[v._v("不过， Kafka 的消息复制机制只能在单个集群里进行，不能在多个集群之间进行。Kafka 提供了 一 个叫作 "),_("strong",[v._v("Mirror Maker")]),v._v(" 的工具，"),_("strong",[v._v("可以用它来实现集群间的消息复制")]),v._v("。")]),v._v(" "),_("h3",{attrs:{id:"为什么选择kafka"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#为什么选择kafka"}},[v._v("#")]),v._v(" 为什么选择Kafka？")]),v._v(" "),_("p",[_("strong",[v._v("1、多生产者")])]),v._v(" "),_("p",[v._v("Kafka 可以无缝地支持多个生产者，不管客户端在使用单个主题还是多个主题。所以"),_("strong",[v._v("它很适合用来从多个前端系统收集数据，并以统一的格式对外提供数据")]),v._v("。")]),v._v(" "),_("p",[_("strong",[v._v("2、多消费者")])]),v._v(" "),_("p",[v._v("支持多个消费者从一个单独的消息流上读取数据，而且消费者之间直不影响。")]),v._v(" "),_("p",[v._v("另外，多个消费者可以组成一个群组，它们共享一个消息流，并保证整个群组对每个给定的消息只处理一次。")]),v._v(" "),_("p",[_("strong",[v._v("3、基于磁盘的数据存储")])]),v._v(" "),_("p",[_("strong",[v._v("允许消费者非实时地读取消息")]),v._v("，这要归功于 Kafka 的 "),_("strong",[v._v("数据保留")]),v._v(" 特性。")]),v._v(" "),_("p",[v._v("消息被提交到磁盘，根据设置的保留规则进行保存。每个主题可以设置单独的保留规则，以便满足不同消费者的需求，各个主题可以保留不同数量的消息。消费者可能会因为处理速度慢或突发的流量高峰导致无陆及时读取消息，而持久化数据可以保证数据不会丢失。")]),v._v(" "),_("p",[_("strong",[v._v("4、伸缩性")])]),v._v(" "),_("p",[v._v("用户在开发阶段可以先使用单个 broker ，再扩展到包含 3 个 broker 的小型开发集群，然后随着数据盐不断增长，部署到生产环境的集群可能包含上百个 broker 。")]),v._v(" "),_("p",[_("strong",[v._v("对在线集群进行扩展丝毫不影响整体系统的可用性")]),v._v("。")]),v._v(" "),_("p",[_("strong",[v._v("5、高性能")])]),v._v(" "),_("p",[v._v("上面提到的所有特性，让 Kafka 成为了一个高性能的发布与订阅消息系统。通过横向扩展生产者、消费者和 broker, Kafka 可以轻松处理巨大的消息流。"),_("strong",[v._v("在处理大量数据的同时，它还能保证亚秒级的消息延迟")]),v._v("。")]),v._v(" "),_("h3",{attrs:{id:"kafka的使用场景"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#kafka的使用场景"}},[v._v("#")]),v._v(" Kafka的使用场景")]),v._v(" "),_("p",[_("strong",[v._v("1 、活动跟踪")])]),v._v(" "),_("p",[v._v("Kafka 最初的使用场景是 "),_("strong",[v._v("跟踪用户的活动")]),v._v("。")]),v._v(" "),_("p",[v._v("网站用户与前端应用程序发生交互 ，前端应用程序生成用户活动相关的悄息。这些消息可以是一些静态的信息，比如页面访问次数和点击量，也可以是一些复杂的操作，比如添加用户资料。这些悄息被发布到一个或多个主题上，由后端应用程序负责读取。")]),v._v(" "),_("p",[_("strong",[v._v("2 、 传递消息")])]),v._v(" "),_("p",[v._v("应用程序向用户 "),_("strong",[v._v("发送通知（比如邮件）")]),v._v(" 就是通过传递消息来实现的。这些应用程序组件可以生成消息，而不需要关心消息的格式，也不需要关心消息是如何被发送的。一个公共应用程序会读取这些消息，对它们进行处理。")]),v._v(" "),_("p",[v._v("使用公共组件的好处在于，不需要在多个应用程序上开发重复的功能，而且可以在公共组件上做一些有趣的转换，比如把多个消息聚合成一个单独的通知，而这些工作是无住在其他地方完成的。")]),v._v(" "),_("p",[_("strong",[v._v("3、度量指标和日志记录")])]),v._v(" "),_("p",[v._v("Kafka 也可以用于收集应用程序和系统度量指标以及日志。")]),v._v(" "),_("p",[v._v("Kafka 支持多个生产者的特性在这个时候就可以派上用场。应用程序定期把度量指标发布到 Kafka 主题上，监控系统或告警系统读取这些消息。")]),v._v(" "),_("p",[v._v("Kafka 也可以用在像 Hadoop 这样的离线系统上，进行较长时间片段的数据分析，比如年度增长走势预测。")]),v._v(" "),_("p",[v._v("日志消息也可以被发布到 Kafka 主题上，然后被路由到专门的日志搜索系统（比如 El ast icsearc h ）或安全分析应用程序。更改目标系统（比如日志存储系统）不会影响到前端应用或聚合方在去，这是 Kafka 的另一个优点。")]),v._v(" "),_("p",[_("strong",[v._v("4、提交日志")])]),v._v(" "),_("p",[v._v("Kafka 的基本概念来惊于 "),_("strong",[v._v("提交日志")]),v._v("，我们可以把数据库的更新发布到 Kafka 上，应用程序通过监控事件流来接收数据库的实时更新。")]),v._v(" "),_("p",[v._v("这种变更日志流也可以用于把数据库的更新复制到远程系统上，或者合并多个应用程序的更新到一个单独的数据库视图上。数据持久化为变更日志提供了缓冲区，也就是说 ，如果消费者应用程序发生故障，可以通过 "),_("strong",[v._v("重放这些日志来恢复系统状态")]),v._v("。")]),v._v(" "),_("p",[_("strong",[v._v("5、 流处理")])]),v._v(" "),_("p",[v._v("提供的功能与 Hadoop 里的 map 和 reduce 有点类似，只不过它们操作的是实时数据流，而 Hadoop WIJ 处理更长时间片段的数据，可能是 几个小时或者几天， Hadoop 会对这些数掘进行批处理。")]),v._v(" "),_("p",[v._v("通过使用流式处理框架，用户可以编写小型应用程序来操作 Kafka 悄息，比如计算度量指标，为其他应用程序有效地处理消息分区，或者对来自多个数据掘的消息进行转换。")]),v._v(" "),_("h2",{attrs:{id:"安装与配置"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#安装与配置"}},[v._v("#")]),v._v(" 安装与配置")]),v._v(" "),_("p",[_("strong",[v._v("Kafka 使用 Zookeeper 保存集群的元数据信息和消费者信息")]),v._v("。 Kafka 发行版自带了Zookeeper ，可以直接从脚本启动，不过安装一个完整版的 Zookeeper 也并不费劲。")]),v._v(" "),_("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://typecho-1300745270.cos.ap-shanghai.myqcloud.com/typora/202203071125373.png",alt:"image-20220307112519112"}}),v._v(" "),_("p",[v._v("Zoo keeper 集群被称为群组。 Zookeeper 使用的是"),_("strong",[v._v("一致性协议")]),v._v("，所以建议每个群组里应该包含奇数个节点（比如 3 个、 5 个等）。")]),v._v(" "),_("p",[v._v("不过，也"),_("strong",[v._v("不建议一个群组包含超过 7 个节点")]),v._v("，因为 Zookeeper 使用了一致性协议，节点过多会降低整个群组的性能。")]),v._v(" "),_("h3",{attrs:{id:"win10安装kafka"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#win10安装kafka"}},[v._v("#")]),v._v(" win10安装Kafka")]),v._v(" "),_("p",[v._v("参看："),_("a",{attrs:{href:"https://blog.csdn.net/github_38482082/article/details/82112641",target:"_blank",rel:"noopener noreferrer"}},[v._v("Win10下kafka简单安装及使用"),_("OutboundLink")],1)]),v._v(" "),_("p",[_("strong",[v._v("启动命令（进入kafka的安装目录）：")])]),v._v(" "),_("p",[v._v("启动内置zookeeper")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[v._v("."),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("\\")]),v._v("bin"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("\\")]),v._v("windows"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("\\")]),v._v("zookeeper-server-start.bat  ."),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("\\")]),v._v("config"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("\\")]),v._v("zookeeper.properties\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[v._v("启动kfka")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[v._v("."),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("\\")]),v._v("bin"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("\\")]),v._v("windows"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("\\")]),v._v("kafka-server-start.bat ."),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("\\")]),v._v("config"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("\\")]),v._v("server.properties\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[_("strong",[v._v("测试")])]),v._v(" "),_("p",[v._v("创建主题：")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[v._v(" ."),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("\\")]),v._v("bin"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("\\")]),v._v("windows"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("\\")]),v._v("kafka-topics.bat "),_("span",{pre:!0,attrs:{class:"token parameter variable"}},[v._v("--create")]),v._v(" --bootstrap-server localhost:9092 --replication-factor "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("1")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token parameter variable"}},[v._v("--partitions")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("1")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token parameter variable"}},[v._v("--topic")]),v._v(" test1\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[v._v("查看主题：")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[v._v("."),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("\\")]),v._v("bin"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("\\")]),v._v("windows"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("\\")]),v._v("kafka-topics.bat "),_("span",{pre:!0,attrs:{class:"token parameter variable"}},[v._v("--list")]),v._v(" --bootstrap-server localhost:9092\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("h3",{attrs:{id:"kafka的配置"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#kafka的配置"}},[v._v("#")]),v._v(" Kafka的配置")]),v._v(" "),_("h4",{attrs:{id:"常规配置"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#常规配置"}},[v._v("#")]),v._v(" 常规配置")]),v._v(" "),_("p",[_("strong",[v._v("1、broker.id")])]),v._v(" "),_("p",[v._v("每个 broker 都需要有一个标识符，使用 b roker.i d 来表示。它的"),_("strong",[v._v("默认值是 0")]),v._v(" ，也可以被设置成其他任意整数。"),_("strong",[v._v("这个值在整个 Kafka 集群里必须是唯一的")]),v._v("。")]),v._v(" "),_("p",[v._v("建议把它们设置成与机器名具有相关性的整数。")]),v._v(" "),_("p",[_("strong",[v._v("2、port")])]),v._v(" "),_("p",[v._v("如果使用配置样本来启动 Kafka ，它会监听 "),_("strong",[v._v("9092 端口")]),v._v("。修改 port配置参数可以把它设置成其他任意可用的端口。")]),v._v(" "),_("p",[_("strong",[v._v("3、zookeeper.connect")])]),v._v(" "),_("p",[v._v("用于保存 broker 元数据的 zookeeper 地址是通过 zookeeper .connect 来指定的。localhost:2181 表示这个 zookeeper 是运行在本地的 2181 端口上。该配置参数是用 冒号分隔的一组 "),_("code",[v._v("hostname:port/path")]),v._v(" 列表。")]),v._v(" "),_("p",[v._v("/path 是可选的 Zookeeper 路径，作为 Kafka 集群的 chroot 环境。如果不指定，默认使用根路径。如果指定的 c hroot 路径不存在， broker 会在启动的时候创建它。")]),v._v(" "),_("p",[_("strong",[v._v("4、log .dirs")])]),v._v(" "),_("p",[_("strong",[v._v("Kafka 把所有消息都保存在磁盘上")]),v._v("，存放这些日志片段的目录是通过 log. dirs 指定的。")]),v._v(" "),_("p",[v._v("如果指定了多个路径，那么 broker 会根据“最少使用”原则，把同一个分区的日志片段保存到同一个路径下。")]),v._v(" "),_("p",[_("strong",[v._v("5、num.recovery . threads.per. data.dir")])]),v._v(" "),_("p",[v._v("对于如下 3 种情况， Kafka 会使用可配置的钱程池来处理日志片段 ：")]),v._v(" "),_("ul",[_("li",[v._v("服务器正常启动，用于打开每个分区的日志片段")]),v._v(" "),_("li",[v._v("服务器崩溃后重启，用于检查和截短每个分区的日志片段")]),v._v(" "),_("li",[v._v("服务器正常关闭，用于关闭日志片段。")])]),v._v(" "),_("p",[v._v("默认情况下 ，每个日志目录只使用一个线程。"),_("strong",[v._v("因为这些线程只是在服务器启动和关闭时会用到 ，所以完全可以设置大量的线程来达到井行操作的目的")]),v._v("。特别是对于包含大量分区的服务器来说， 一旦发生崩愤，在进行恢复时使用井行操作可能会省下数小时的时间。")]),v._v(" "),_("p",[_("strong",[v._v("设置此参数时需要注意，所配置的数字对应的是 log. dirs 指定的单个日志目录")]),v._v("。 也就是说，如果 num.recovery . threads.per. data.dir 被设为 8 ， 井且 log .dirs 指定了 3 个路径，那么总共需要 24 个线程。")]),v._v(" "),_("p",[_("strong",[v._v("6、auto.create .topics.enable")])]),v._v(" "),_("p",[v._v("默认情况下， Kafka 会在如下几种情形下自动创建主题 ：")]),v._v(" "),_("ul",[_("li",[v._v("当一个生产者开始往主题写入消息时")]),v._v(" "),_("li",[v._v("当一个消费者开始从主题读取消息时")]),v._v(" "),_("li",[v._v("当任意一个客户端向主题发送元数据请求时。")])]),v._v(" "),_("p",[_("strong",[v._v("很多时候，这些行为都是非预期的")]),v._v("。而且，根据 Kafka 协议，如果一个主题不先被创建，根本无法知道它是否已经存在。")]),v._v(" "),_("p",[v._v("如果显式地创建主题 ， 不管是手动创建还是通过其他配置系统来创建，都可以把 auto.create .topics.enable 设为 false 。")]),v._v(" "),_("h4",{attrs:{id:"主题的默认配置"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#主题的默认配置"}},[v._v("#")]),v._v(" 主题的默认配置")]),v._v(" "),_("p",[_("strong",[v._v("1、num.partions")])]),v._v(" "),_("p",[v._v("num.partions 参数指定了 "),_("strong",[v._v("新创建的主题将包含多少个分区")]),v._v("。")]),v._v(" "),_("p",[_("strong",[v._v("如果启用了主题自动创建功能（该功能默认是启用的），主题分区的个数就是该参数指定的值")]),v._v("。该参数的默认值是 1 。")]),v._v(" "),_("p",[v._v("要注意，"),_("strong",[v._v("我们可以增加主题分区的个数，但不能减少分区的个数")]),v._v("。所以，"),_("strong",[v._v("如果耍让一个主题的分区个数少于 num.partions 指定的值，需要手动创建主题")]),v._v("。")]),v._v(" "),_("p",[v._v("如何选定分区数量？主要考虑一下几个方面的因素：")]),v._v(" "),_("ul",[_("li",[v._v("主题需要达到多大的吞吐量？例如，是希望每秒钟写入 IOOKB 还是1GB？")]),v._v(" "),_("li",[v._v("从单个分区读取数据的最大吞吐量是多少？每个分区一般都会有一个消费者，如果你知道消费者将数据写入数据库的速度不会超过每秒 50MB ，那么你也该知道，从一个分区读取数据的吞吐量不需要超过每秒 50MB 。")]),v._v(" "),_("li",[v._v("可以通过类似的方法估算生产者向单个分区写入数据的吞吐量，不过生产者的速度一般比消费者快得多，所以最好为生产者多估算一些吞吐量。")]),v._v(" "),_("li",[v._v("每个 broker 包含的分区个数、可用的磁盘空间和网络带宽。")]),v._v(" "),_("li",[v._v("如果消息是按照不同的键采写入分区的，那么为已有的主题新增分区就会很困难。")]),v._v(" "),_("li",[v._v("单个 broker 对分区个数是有限制的，因为分区越多，占用的内存越多，完成首领选举需要的时间也越长。")])]),v._v(" "),_("p",[v._v("如果你估算出主题的吞吐量和消费者吞吐量，"),_("strong",[v._v("可以用主题吞吐量除以消费者吞吐量算出分区的个数")]),v._v("。")]),v._v(" "),_("p",[v._v("如果每秒钟要从主题上写入和读取 1GB 的数据，并且每个消费者每秒钟可以处理 50MB的数据，那么至少需要 20 个分区。这样就可以让 20 个消费者同时读取这些分区，从而达到每秒钟 1GB 的吞吐量。")]),v._v(" "),_("p",[_("strong",[v._v("如果不知道这些信息，那么根据经验，把分区的大小限制在 25GB 以内可以得到比较理想的效果")]),v._v("。")]),v._v(" "),_("p",[_("strong",[v._v("2、log.retention.ms")])]),v._v(" "),_("p",[_("strong",[v._v("Kafka 通常根据时间来决定数据可以被保留多久")]),v._v("。默认使用 "),_("strong",[v._v("log.retention.hour")]),v._v(" 参数来配置时间 ，"),_("strong",[v._v("默认值为 168 小时，也就是一周")]),v._v("。除此以外，还有其他两个参数 log.retention.minutes、log.retention.ms 。"),_("strong",[v._v("如果指定了不止一个参数， Kafka 会优先使用具有最小值的那个参数")]),v._v("。")]),v._v(" "),_("p",[_("strong",[v._v("根据时间保留数据是通过检查磁盘上日志片段文件的最后修改时间来实现的")]),v._v("。一般来说，最后修改时间指的就是日志片段的关闭时间，也就是"),_("strong",[v._v("文件里最后一个消息的时间戳")]),v._v("。")]),v._v(" "),_("p",[_("strong",[v._v("3、log.retention.bytes")])]),v._v(" "),_("p",[v._v("另 一 种方式是"),_("strong",[v._v("通过保留的消息字节数来判断消息是否过期")]),v._v("。")]),v._v(" "),_("p",[v._v("如果有一个包含 8 个分区的主题，井且 log.retention.bytes 被设为 lGB ，那么这个主题最多可以保留 8GB 的数据。所以，"),_("strong",[v._v("当主题的分区个数增加时，整个主题可以保留的数据也随之增加")]),v._v("。")]),v._v(" "),_("p",[v._v("如果同时指定了 log.retention.ms 和 log.retention.bytes （或者另 一 个时间参数），"),_("strong",[v._v("只要任意一个条件得到满足，消息就会被删除")]),v._v("。")]),v._v(" "),_("p",[_("strong",[v._v("4、log.segment.bytes")])]),v._v(" "),_("p",[v._v("以上的设置都作用在日志片段上，而不是作用在单个消息上。当消息到达 broker 时，它们被迫加到分区的当前日志片段上。")]),v._v(" "),_("p",[v._v("当日志片段大小达到 log.segment.bytes 指定的上限（默认是 lGB ）时，当前日志片段就会被关闭，一个新的日志片段被打开。")]),v._v(" "),_("p",[v._v("如果一个日志片段被关闭，就开始等待过期。"),_("strong",[v._v("这个参数的值越小，就会越频繁地关闭和分配新文件，从而降低磁盘写入的整体效率")]),v._v("。")]),v._v(" "),_("p",[v._v("如果主题的消息量不大，那么如何调整这个参数的大小就变得尤为重要。")]),v._v(" "),_("p",[v._v("例如，如果一个主题每天只接收 100MB 的消息，而 log.segment.bytes 使用默认设置，那么需要 10 天时间才能填满一个日志片段。"),_("strong",[v._v("因为在日志片段被关闭之前消息是不会过期的")]),v._v("，所以如果 log.retention.ms 被设为 604 800 000 （ 也就是 1 周），那么日志片段最多需要 17 天才会过期。这是因为关闭日志片段需要 10 天的时间，而根据配置的过期时间，还需要再保留 7 天时间（要等到日志片段里的最后一个消息过期才能被删除） 。")]),v._v(" "),_("p",[v._v("日志片段的大小会影响 "),_("strong",[v._v("使用时间戳获取偏移量")]),v._v("。在使用时间戳获取日志偏移量时， Kafka 会检查分区里最后修改时间大于指定时间戳的日志片段（已经被关闭的），该日志片段的前一个文件的最后修改时间小子指定时向戳。然后， Kafka 返回该日志片段（也就是文件名）开头的偏移量。"),_("strong",[v._v("对于使用时间戳获取偏移量的操作来说，日志片段越小，结果越准确")]),v._v("。")]),v._v(" "),_("p",[_("strong",[v._v("5、log.segment.ms")])]),v._v(" "),_("p",[v._v("另 一个可以控制日志片段关闭时间的参数是 log.segment.ms 时，"),_("strong",[v._v("它指定了 多长时间之后日志片段会被关闭")]),v._v("。")]),v._v(" "),_("p",[_("strong",[v._v("6、message.max.bytes")])]),v._v(" "),_("p",[v._v("该参数 "),_("strong",[v._v("用来限制单个消息的大小")]),v._v("，默认值是 1 000 000 ，也就是 lMB")]),v._v(" "),_("p",[v._v("如果生产者尝试发送的消息超过这个大小，不仅消息不会被接收，还会收到broker 返回的错误信息。跟其他与字节相关的配置参数一样 ，"),_("strong",[v._v("该参数指的是压缩后的消息大小")]),v._v("，也就是说，只要压缩后的消息小于 message.max.bytes 指定的值，"),_("strong",[v._v("消息的实际大小可以远大于这个值")]),v._v("。")]),v._v(" "),_("p",[_("strong",[v._v("这个值对性能有显著的影响")]),v._v("。值越大，那么负责处理网络连接和请求的线程就需要花越多的时间来处理这些请求。它还会增加磁盘写入块的大小，从而影响 IO 吞吐量。")]),v._v(" "),_("p",[_("strong",[v._v("在服务端和客户端之间协调消息大小的配置")])]),v._v(" "),_("p",[v._v("消费者客户端设置的 fetch .message.max.bytes  必须与服务器端设置的消息大小进行协调。"),_("strong",[v._v("如果这个值比 message.max.bytes 小，那么消费者就无法读取比较大的消息，导致出现消费者被阻塞的情况")]),v._v("。")]),v._v(" "),_("p",[v._v("在为集群里的 broker 配置 "),_("strong",[v._v("replace.fetch.max.bytes")]),v._v(" 参数时 ， 也遵循同样的原则。")]),v._v(" "),_("h4",{attrs:{id:"硬件配置"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#硬件配置"}},[v._v("#")]),v._v(" 硬件配置")]),v._v(" "),_("p",[_("strong",[v._v("1、磁盘吞吐量")])]),v._v(" "),_("p",[v._v("生产者客户端的性能直接受到服务器端磁盘吞吐量的影响。生产者生成的消息必须被提交到服务器保存，大多数客户端在发送消息之后会一直等待，直到至少有一个服务器确认消息已经成功提交为止。 也就是说，"),_("strong",[v._v("磁盘写入速度越快，生成消息的延迟就越低")]),v._v("。")]),v._v(" "),_("p",[_("strong",[v._v("2、磁盘容量")])]),v._v(" "),_("p",[v._v("需要多大的磁盘容量取决于需要保留的消息数量。如果服务器每天会收到 1TB 消息，并且保留 7 天，那么就需要 7TB 的存储空间，而且还要为其他文件提供至少 10 % 的额外空间。除此之外，还需要提供缓冲区，用于应付消息流量的增长和波动。")]),v._v(" "),_("p",[_("strong",[v._v("3、内存")])]),v._v(" "),_("p",[v._v("磁盘性能影响生产者 ，而内存影响消费者。 消费者一般从分区尾部读取消息，如果有生产者存在，就紧跟在生产者后面。在这种情况下，"),_("strong",[v._v("消费者读取的消息会直接存放在系统的页面缓存里，这比从磁盘上重新读取要快得多")]),v._v(" 。")]),v._v(" "),_("p",[v._v("运行 Kafka 的 JVM 不需要太大的内存，"),_("strong",[v._v("剩余的系统内存可以用作页面缓存，或者用来缓存正在使用中 的日志片段")]),v._v("。"),_("strong",[v._v("这也就是为什么不建议把 Kafka 同其他重要的应用程序部署在一起的原因")]),v._v("，"),_("strong",[v._v("它们需要共享页面缓存，最终会降低 Kafka 消费者的性能")]),v._v("。")]),v._v(" "),_("p",[_("strong",[v._v("4、网络")])]),v._v(" "),_("p",[v._v("网络吞吐量决定了 Kafka 能够处理的最大数据流量。")]),v._v(" "),_("p",[_("strong",[v._v("5、CPU")])]),v._v(" "),_("p",[v._v("与磁盘和内存相比， "),_("strong",[v._v("Kafka 对计算处理能力的要求相对较低")]),v._v("，不过它在一定程度上还是会影响整体的性能。")]),v._v(" "),_("p",[v._v("客户端为了优化网络和磁盘空间，会对消息进行压缩。 服务器需要对消息进行批量解压，设置偏移量，然后重新进行批量压缩，再保存到磁盘上 。 这就是Kafka 对计算处理能力有所要求的地方。")]),v._v(" "),_("h4",{attrs:{id:"kafka集群"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#kafka集群"}},[v._v("#")]),v._v(" Kafka集群")]),v._v(" "),_("p",[v._v("使用集群最大的好处是 "),_("strong",[v._v("可以跨服务器进行负载均衡")]),v._v("，再则就是 "),_("strong",[v._v("可以使用复制功能来避免因单点故障造成的数据丢失")]),v._v("。")]),v._v(" "),_("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://typecho-1300745270.cos.ap-shanghai.myqcloud.com/typora/202203071715163.png",alt:"image-20220307171544089"}}),v._v(" "),_("p",[_("strong",[v._v("1、需要多少个broker")])]),v._v(" "),_("p",[v._v("取决因素：")]),v._v(" "),_("ol",[_("li",[_("p",[_("strong",[v._v("需要多少磁盘空间来保留数据，以及单个 broker 有多少空间可用")]),v._v("。")]),v._v(" "),_("p",[v._v("如果整个集群需要保留 10TB 的数据， 每个broker 可以存储 2TB ，那么至少需要 5 个 broker 。如果启用了数据复制，那么至少还需要一倍的空间，不过这要取决于配置的复制系数是多少。")])]),v._v(" "),_("li",[_("p",[_("strong",[v._v("集群处理请求的能力")]),v._v("。")]),v._v(" "),_("p",[v._v("如果单个 broker 的网络接口在高峰时段可以达到 80 % 的使用量，并且有两个消费者，那么消费者就无桂保持峰值，除非有两个 broker 。如果集群启用了复制功能，则要把这个额外的消费者考虑在内。")])])]),v._v(" "),_("h4",{attrs:{id:"jvm调优"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#jvm调优"}},[v._v("#")]),v._v(" JVM调优")]),v._v(" "),_("p",[v._v("以下是 Gl 的两个调整参数：")]),v._v(" "),_("p",[v._v("1、"),_("code",[v._v("MaxGCPauseMillis")]),v._v("："),_("strong",[v._v("该参数指定每次垃圾回收默认的停顿时间")]),v._v("。值不是固定的， Gl 可以根据需要使用更长的时间。它的"),_("strong",[v._v("默认值是 200ms")]),v._v(" 。也就是说， Gl 会决定垃圾回收的频率以及每一轮需要回收多少个区域，这样算下来 ， 每一轮垃圾回收大概需要 200ms 的时间。")]),v._v(" "),_("p",[v._v("2、"),_("code",[v._v("InitiatingHeapOccupancyPercent")]),v._v("：该参数指定了在 G1 启动新一轮垃坡回收之前可以使用的堆内存百分比，"),_("strong",[v._v("默认值是 45")]),v._v(" 。\n也就是况，"),_("strong",[v._v("在堆内存的使用率达到 45 % 之前， Gl 不会启动垃圾回收。这个百分比包括新生代和老年代的内存")]),v._v("。")]),v._v(" "),_("p",[_("strong",[v._v("Kafka 对堆内存的使用率非常高，容易产生垃坡对象，所以可以把这些值设得小一些")]),v._v("。")]),v._v(" "),_("p",[v._v("如果一台服务器有 64GB 内 存，井且使用 5 GB 堆内存来运行 Kafka ，那么可以参考以下的配置："),_("code",[v._v("MaxGCPauseMillis")]),v._v(" 可以设为 "),_("code",[v._v("20 ms")]),v._v(" ；"),_("code",[v._v("InitiatingHeapOccupancyPercent")]),v._v(" 可以设为 "),_("code",[v._v("35")]),v._v(" ，"),_("strong",[v._v("这样可以让垃圾回收比默认的要早一些启动")]),v._v("。")]),v._v(" "),_("p",[v._v("Kafka 的 启动脚本井没有启用 G l 回收器，而是使用了 Parallel New 和 CMS 垃圾回收器。不过它可以通过环境变量来修改。")])])}),[],!1,null,null,null);_.default=r.exports}}]);